{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 id=\"random-forest-regressor-algorithm\" align=\"center\">üå≤ Random Forest Regressor Algorithm üå≤</h1>\n\n<center><i>A Forest of Decision Trees<i></center>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"----\n\n<h1 id='brief-description'>üìù Brief Description</h1>\n\n`Random Forest Regressor` Algorithm consists in a group of `Decision Trees` to predict values.\n\n<center>\n<img src='https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmiro.medium.com%2Fmax%2F567%2F1*Mb8awDiY9T6rsOjtNTRcIg.png&f=1&nofb=1&ipt=c968cd83d2ee1132fa978557078fea03427bc90732cf03b8a1ace773961e1849&ipo=images' />\n</center>\n\n<br />\n\n**‚úîÔ∏è Pros:**\n\n```\n- Random Forests can be used for both classification and regression tasks;\n\n- Random Forests work well with both categorical and numerical data. No scaling or transformation of variables is usually necessary;\n\n- Random Forests implicitly perform feature selection and generate uncorrelated decision trees. It does this by choosing a random set of features to build each decision tree. This also makes it a great model when you have to work with a high number of features in the data;\n\n- Random Forests are not influenced by outliers to a fair degree. It does this by binning the variables;\n\n- Random Forests can handle linear and non-linear relationships well;\n\n- Random Forests generally provide high accuracy and balance the bias-variance trade-off well. Since the model‚Äôs principle is to average the results across the multiple decision trees it builds, it averages the variance as well.\n```\n\n<br />\n\n**‚ùå Cons:**\n\n```\n- Random Forests are not easily interpretable. They provide feature importance but it does not provide complete visibility into the coefficients as linear regression;\n\n- Random Forests can be computationally intensive for large datasets;\n\n- Random forest is like a black box algorithm, you have very little control over what the model does.\n```\n\n<br />\n\n**üìõ Some Random Forest Regressor Properties:**\n\n```\n- n_estimators: number of Decision Trees\n- max_depth: max depth for each Decision Tree\n- criterion: evaluation method\n- random_state: integer number for results reproducability\n```","metadata":{}},{"cell_type":"markdown","source":"----\n\n<h1 id='reach-me'>‚ÑπÔ∏è Further Information</h1>\n<br/>\n\nFor further information, check out these two videos from *[StatQuest with Josh Starmer](https://www.youtube.com/@statquest)* YouTube channel:\n\n- *[StatQuest: Random Forests Part 1 - Building, Using and Evaluating](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ)*\n- *[StatQuest: Random Forests Part 2: Missing data and clustering](https://www.youtube.com/watch?v=sQ870aTKqiM)*","metadata":{}},{"cell_type":"markdown","source":"----\n\n<h1 id='example-code'>üíª Example Code</h1>\n<br/>\n\nLet's use `Scikit Learn` package to demonstrate how to create, fit, make predictions and evaluate a simple `Random Forest Regressor Model`.\n\nTo evaluation, we will be using the `Mean Squared Error (MSE)` Algorithm. This Algorithm works getting the absolute value of the substraction between the predicted values by the real ones. After that, we calculate the summatory between them and finds out their mean. The method can be repreented by the following equation:\n\n$mean(sum(abs(predictedvalues - realvalues)))$\n\n\nNow, let's hop into the code!!","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\nSEED = (2000)\nX_MIN = 0\nX_MAX = 100\nY_MIN = 0\nY_MAX = 20\nTRAIN_SAMPLES = (800)\nVALID_SAMPLES = (200)\n\nnp.random.seed(SEED)\npd.set_option('display.max_rows', 15)\npd.set_option('display.max_columns', 15)","metadata":{"execution":{"iopub.status.busy":"2022-12-19T00:13:54.851025Z","iopub.execute_input":"2022-12-19T00:13:54.851456Z","iopub.status.idle":"2022-12-19T00:13:54.859275Z","shell.execute_reply.started":"2022-12-19T00:13:54.851419Z","shell.execute_reply":"2022-12-19T00:13:54.857292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generating fake dataset\nX_train = np.random.randint(X_MIN, X_MAX, TRAIN_SAMPLES)\nX_valid = np.random.randint(X_MIN, X_MAX, VALID_SAMPLES)\ny_train = np.random.randint(Y_MIN, Y_MAX, TRAIN_SAMPLES)\ny_valid = np.random.randint(Y_MIN, Y_MAX, VALID_SAMPLES)\n\nX_train = pd.DataFrame(X_train, columns=['X'])\nX_valid = pd.DataFrame(X_valid, columns=['X'])\ny_train = pd.DataFrame(y_train, columns=['y'])\ny_valid = pd.DataFrame(y_valid, columns=['y'])","metadata":{"execution":{"iopub.status.busy":"2022-12-19T00:13:55.148888Z","iopub.execute_input":"2022-12-19T00:13:55.149768Z","iopub.status.idle":"2022-12-19T00:13:55.161111Z","shell.execute_reply.started":"2022-12-19T00:13:55.149731Z","shell.execute_reply":"2022-12-19T00:13:55.159481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the Model\nrfg_model = RandomForestRegressor(\n    n_estimators=250\n    , max_depth=10\n    , criterion='squared_error'\n    , random_state=SEED\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-19T00:13:55.503913Z","iopub.execute_input":"2022-12-19T00:13:55.504394Z","iopub.status.idle":"2022-12-19T00:13:55.509703Z","shell.execute_reply.started":"2022-12-19T00:13:55.504360Z","shell.execute_reply":"2022-12-19T00:13:55.508805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training and Making Predictions\nrfg_model.fit(X_train, y_train)\nprint('Traning Done!')\n\npredictions = rfg_model.predict(X_valid)\nprint('Predictions Done!')","metadata":{"execution":{"iopub.status.busy":"2022-12-19T00:13:55.910491Z","iopub.execute_input":"2022-12-19T00:13:55.911475Z","iopub.status.idle":"2022-12-19T00:13:56.343906Z","shell.execute_reply.started":"2022-12-19T00:13:55.911424Z","shell.execute_reply":"2022-12-19T00:13:56.342174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation\nmse = mean_squared_error(y_valid, predictions)\ntrain_score = round(rfg_model.score(X_train, y_train) * 100, 2)\nvalid_score = round(rfg_model.score(X_valid, y_valid) * 100, 2)\n\nprint('Mean Squared Error (MSE):', mse)","metadata":{"execution":{"iopub.status.busy":"2022-12-19T00:16:50.914403Z","iopub.execute_input":"2022-12-19T00:16:50.914824Z","iopub.status.idle":"2022-12-19T00:16:51.007026Z","shell.execute_reply.started":"2022-12-19T00:16:50.914773Z","shell.execute_reply":"2022-12-19T00:16:51.005475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**OBS.:** *as far as the goal of this Kernel is to explain what is and how to apply `Random Forest Regressor Algorithm`, we have not done any Data Preprocessing and Transformation, so our model's evaluation is quite suck! Do not worry about this üòÇ*","metadata":{}},{"cell_type":"markdown","source":"----\n\nThank so much for today, see ya!! üëãüëã\n\n<br/>\n<h1 id='reach-me'>üì´ Reach Me</h1>\n<br/>\n\n> **Email:** **[csfelix08@gmail.com](mailto:csfelix08@gmail.com?)**\n\n> **Linkedin:** **[linkedin.com/in/csfelix/](https://www.linkedin.com/in/csfelix/)**\n\n> **Instagram:** **[instagram.com/c0deplus/](https://www.instagram.com/c0deplus/)**\n\n> **Portfolio:** **[CSFelix.io](https://csfelix.github.io/)**\n\n> **Kaggle:** **[DSFelix](https://www.kaggle.com/dsfelix)**","metadata":{}}]}